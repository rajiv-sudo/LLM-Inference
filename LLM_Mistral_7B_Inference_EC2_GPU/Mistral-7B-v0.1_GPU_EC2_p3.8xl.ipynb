{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4444835-70c4-4c0f-a9e5-8bdbacc2e605",
   "metadata": {},
   "source": [
    "## LLM Inference on P3.8xlarge EC2 Instance\n",
    "This EC2 instance has 4 NVIDIA Tesla V100 GPUs. We will run inference on the mistralai/Mistral-7B-v0.1 model using GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2601697-2265-40ec-9a34-e6fae91be8ae",
   "metadata": {},
   "source": [
    "## Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81510468-f07a-4cb6-838e-a01e8648e75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in ./cuda_tutorial/lib/python3.10/site-packages (4.40.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./cuda_tutorial/lib/python3.10/site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./cuda_tutorial/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in ./cuda_tutorial/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./cuda_tutorial/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./cuda_tutorial/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./cuda_tutorial/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./cuda_tutorial/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: filelock in ./cuda_tutorial/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./cuda_tutorial/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./cuda_tutorial/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./cuda_tutorial/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./cuda_tutorial/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./cuda_tutorial/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./cuda_tutorial/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./cuda_tutorial/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./cuda_tutorial/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: huggingface_hub in ./cuda_tutorial/lib/python3.10/site-packages (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.9 in ./cuda_tutorial/lib/python3.10/site-packages (from huggingface_hub) (24.0)\n",
      "Requirement already satisfied: filelock in ./cuda_tutorial/lib/python3.10/site-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./cuda_tutorial/lib/python3.10/site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./cuda_tutorial/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./cuda_tutorial/lib/python3.10/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./cuda_tutorial/lib/python3.10/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: requests in ./cuda_tutorial/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./cuda_tutorial/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./cuda_tutorial/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./cuda_tutorial/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./cuda_tutorial/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q accelerate\n",
    "!pip install transformers\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf4602-282d-4023-a496-1290e9cd3385",
   "metadata": {},
   "source": [
    "## Log into Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aeb281e-ce1c-4db3-97b8-1accc56ab1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d3bcc2042514cf88985f3d77c43c5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9670735-75ca-45b7-8536-0194c8bc1d63",
   "metadata": {},
   "source": [
    "## Load the model and Tokenizer from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62612da-232a-4639-8dd3-bd8959214846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b214fbfcc440099c4a609408fb3138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfda04a-e64d-48ac-967f-f734bb417e5b",
   "metadata": {},
   "source": [
    "## Run the inference on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7c42ca-98fb-47d4-90b2-237298be7505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write be a 150 word essay Why is health important to everyone?\n",
      "\n",
      "Health is important to everyone because it is the foundation of a happy and productive life. Without good health, it is difficult to enjoy life and achieve our goals. Good health allows us to be active, productive, and engaged in our communities. It also helps us to avoid illness and injury, which can be costly and disruptive to our lives.\n",
      "\n",
      "Good health is also essential for our mental and emotional well-being. When we are healthy, we are better able to cope with stress and handle the challenges of life. We are also more likely to have positive relationships with others and to feel a sense of purpose and meaning in our lives.\n",
      "\n",
      "In addition, good health is important for our economic well-being. When we are healthy, we are more likely to be productive and to contribute to the economy. We are also less likely to need costly medical care, which can be a burden on our finances.\n",
      "\n",
      "Overall, good health is essential for a happy and productive life. It is the foundation of our physical, mental, and emotional well-being, and it is essential for our economic well-being as well.\n",
      "Number of tokens generated:  250\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "text = \"Write be a 150 word essay Why is health important to everyone?\"\n",
    "device = \"cuda\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Get start time\n",
    "t1 = time.time()\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=300)\n",
    "\n",
    "# Get end time\n",
    "t2 = time.time()\n",
    "\n",
    "# Get total time taken\n",
    "t3 = t2 - t1\n",
    "\n",
    "response = (tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(response)\n",
    "\n",
    "# Calculate the number of output tokens\n",
    "tokens = tokenizer.tokenize(response)\n",
    "num_tokens = (len(tokens))\n",
    "print(\"Number of tokens generated: \", num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e5e7f-6449-4093-ae67-5f1fd1bf8964",
   "metadata": {},
   "source": [
    "## Calculate Throughput anf total time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a786c73f-2b8b-4ce2-8c05-e0cecccbd08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.798798084259033 : seconds\n",
      "Number of Tokens per second:  13.298722550211055\n"
     ]
    }
   ],
   "source": [
    "# Print total time taken\n",
    "print(t3,\": seconds\")\n",
    "\n",
    "# Calculate tokens per secon\n",
    "tokens_per_second = num_tokens/t3\n",
    "\n",
    "print(\"Number of Tokens per second: \", tokens_per_second)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
