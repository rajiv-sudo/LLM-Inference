{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a61c788-992c-4b99-af1b-a281c3654be2",
   "metadata": {},
   "source": [
    "## Inferencing on P3.2xlarge EC2 instance with NVIDIA Tesla V100 GPU\n",
    "We will be using the model mistralai/Mistral-7B-v0.1 from Huggingface Transformers. This is a 7.24B parameter model with native precision of BF16. This model with native precision is too big to fit on the GPU memory of this machine. Hence, we will need to quantize the model to lower precision before loading the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862a103-6820-443c-bfd8-7f98c8d3e167",
   "metadata": {},
   "source": [
    "## Quantize the model from BF16 to INT8 using Quanto\n",
    "Quanto library is a versatile pytorch quantization toolkit. The quantization method used is the linear quantization. Quanto provides several unique features. We will use the weights quantization (float8,int8,int4,int2). Specifically INT8 quantization of the model's weights.\n",
    "\n",
    "Reference - https://huggingface.co/docs/transformers/main/en/quantization#quanto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ecf9b9-301b-4b80-9f69-ae40d298fd77",
   "metadata": {},
   "source": [
    "## Install Huggingface Transformers, Quanto and other neccessary packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf58e2c0-73ab-4057-89fa-a10649469bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q git+https://github.com/huggingface/transformers.git\n",
    "!pip install -U -q quanto\n",
    "!pip install -U -q accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15fdfe-f2d9-4f85-be12-6979977383ac",
   "metadata": {},
   "source": [
    "## Log into Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee1e2d-8659-439b-a84f-38f8c68523f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1dadbf-3fe2-4f32-ad54-4a7101272314",
   "metadata": {},
   "source": [
    "## Perform the quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688e3df7-b346-41ae-9e02-26bd1171156a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824cadee109343b8ac60bed78ba75202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, QuantoConfig\n",
    "import torch\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "quantization_config = QuantoConfig(weights=\"int8\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, quantization_config=quantization_config, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec1d22c-1216-48bd-ae4d-142b4e269f8c",
   "metadata": {},
   "source": [
    "## Perform the response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350ae50b-dbf6-4e9d-9604-b6180aecad9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ops.py:52: UserWarning: An exception was raised while calling the optimized kernel for quanto::dqmm: Error building extension 'quanto_cpp': [1/5] c++ -MMD -MF pybind_module.o.d -DTORCH_EXTENSION_NAME=quanto_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/TH -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/pybind_module.cpp -o pybind_module.o \n",
      "\u001b[31mFAILED: \u001b[0mpybind_module.o \n",
      "c++ -MMD -MF pybind_module.o.d -DTORCH_EXTENSION_NAME=quanto_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/TH -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/pybind_module.cpp -o pybind_module.o \n",
      "In file included from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/Device.h:4,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/python.h:8,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/extension.h:9,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/pybind_module.cpp:1:\n",
      "/home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/python_headers.h:12:10: fatal error: Python.h: No such file or directory\n",
      "   12 | #include <Python.h>\n",
      "      |          ^~~~~~~~~~\n",
      "compilation terminated.\n",
      "[2/5] c++ -MMD -MF unpack.o.d -DTORCH_EXTENSION_NAME=quanto_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/TH -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/unpack.cpp -o unpack.o \n",
      "\u001b[31mFAILED: \u001b[0munpack.o \n",
      "c++ -MMD -MF unpack.o.d -DTORCH_EXTENSION_NAME=quanto_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/TH -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/unpack.cpp -o unpack.o \n",
      "In file included from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/Device.h:4,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/python.h:8,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/extension.h:9,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/unpack.h:1,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/unpack.cpp:1:\n",
      "/home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/python_headers.h:12:10: fatal error: Python.h: No such file or directory\n",
      "   12 | #include <Python.h>\n",
      "      |          ^~~~~~~~~~\n",
      "compilation terminated.\n",
      "[3/5] c++ -MMD -MF mm.o.d -DTORCH_EXTENSION_NAME=quanto_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/TH -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/mm.cpp -o mm.o \n",
      "\u001b[31mFAILED: \u001b[0mmm.o \n",
      "c++ -MMD -MF mm.o.d -DTORCH_EXTENSION_NAME=quanto_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/TH -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/mm.cpp -o mm.o \n",
      "In file included from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/Device.h:4,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/python.h:8,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/extension.h:9,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/mm.h:1,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/mm.cpp:1:\n",
      "/home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/python_headers.h:12:10: fatal error: Python.h: No such file or directory\n",
      "   12 | #include <Python.h>\n",
      "      |          ^~~~~~~~~~\n",
      "compilation terminated.\n",
      "[4/5] c++ -MMD -MF quantize.o.d -DTORCH_EXTENSION_NAME=quanto_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/TH -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/quantize.cpp -o quantize.o \n",
      "\u001b[31mFAILED: \u001b[0mquantize.o \n",
      "c++ -MMD -MF quantize.o.d -DTORCH_EXTENSION_NAME=quanto_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/TH -isystem /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -c /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/quantize.cpp -o quantize.o \n",
      "In file included from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/Device.h:4,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/api/include/torch/python.h:8,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/extension.h:9,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/quantize.h:1,\n",
      "                 from /home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ext/cpp/quantize.cpp:1:\n",
      "/home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/torch/include/torch/csrc/python_headers.h:12:10: fatal error: Python.h: No such file or directory\n",
      "   12 | #include <Python.h>\n",
      "      |          ^~~~~~~~~~\n",
      "compilation terminated.\n",
      "ninja: build stopped: subcommand failed.\n",
      " Falling back to default implementation.\n",
      "  warnings.warn(message + \" Falling back to default implementation.\")\n",
      "/home/ubuntu/cuda_tutorial/lib/python3.10/site-packages/quanto/library/ops.py:52: UserWarning: An exception was raised while calling the optimized kernel for quanto::dqmm: /home/ubuntu/.cache/torch_extensions/py310_cu118/quanto_cpp/quanto_cpp.so: cannot open shared object file: No such file or directory Falling back to default implementation.\n",
      "  warnings.warn(message + \" Falling back to default implementation.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write be a 150 word essay Why is health important to everyone?\n",
      "\n",
      "Health is important to everyone because it is the foundation of a happy and productive life. Without good health, it is difficult to enjoy life and achieve oneâ€™s goals. Good health allows us to be active, productive, and engaged in our communities. It also helps us to avoid illness and injury, which can be costly and disruptive to our lives.\n",
      "\n",
      "Good health is also important for our mental and emotional well-being. When we are healthy, we are more likely to feel confident, happy, and fulfilled. We are also better able to cope with stress and challenges in our lives.\n",
      "\n",
      "Finally, good health is important for our relationships with others. When we are healthy, we are more likely to be able to participate in activities with our friends and family, and to be a positive influence in their lives.\n",
      "\n",
      "In conclusion, health is important to everyone because it is the foundation of a happy and productive life. It allows us to be active, productive, and engaged in our communities, and it helps us to avoid illness and injury. It is also important for our mental and emotional well-being, and for our relationships with others.\n",
      "Number of tokens generated:  254\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "text = \"Write be a 150 word essay Why is health important to everyone?\"\n",
    "device = \"cuda\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Get start time\n",
    "t1 = time.time()\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=300)\n",
    "\n",
    "# Get end time\n",
    "t2 = time.time()\n",
    "\n",
    "# Get total time taken\n",
    "t3 = t2 - t1\n",
    "\n",
    "response = (tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(response)\n",
    "\n",
    "# Calculate the number of output tokens\n",
    "tokens = tokenizer.tokenize(response)\n",
    "num_tokens = (len(tokens))\n",
    "print(\"Number of tokens generated: \", num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3404495-ffea-4870-9c2e-2091bd5c7b93",
   "metadata": {},
   "source": [
    "## Calculate total time and throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4a9670-9b46-48a1-8f32-ddb399f1bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.7796630859375 : seconds\n",
      "Number of Tokens per second:  5.801780600764548\n"
     ]
    }
   ],
   "source": [
    "# Print total time taken\n",
    "print(t3,\": seconds\")\n",
    "\n",
    "# Calculate tokens per secon\n",
    "tokens_per_second = num_tokens/t3\n",
    "\n",
    "print(\"Number of Tokens per second: \", tokens_per_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ee4a7-c780-42bd-9e8e-79cda86e4c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
